{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e19a4b",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 2\n",
    "## Работа с алгоритмами логистической и линейной регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673c0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    roc_curve\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, \n",
    "    mean_squared_error, \n",
    "    r2_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения графиков\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4b5fc0",
   "metadata": {},
   "source": [
    "## Загрузка и изучение данных\n",
    "\n",
    "Использую те же датасеты, что и в первой лабораторной работе:\n",
    "- Для логистической регрессии: данные детекции дыма (классификация)\n",
    "- Для линейной регрессии: цены подержанных автомобилей (регрессия)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1996c9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ДАННЫЕ ДЛЯ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\n",
      "Размер датасета: (62630, 16)\n",
      "Распределение классов:\n",
      "Fire Alarm\n",
      "1    0.714626\n",
      "0    0.285374\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== ДАННЫЕ ДЛЯ ЛИНЕЙНОЙ РЕГРЕССИИ ===\n",
      "Размер датасета: (4009, 12)\n",
      "\n",
      "Пример данных:\n",
      "     brand                            model  model_year      milage  \\\n",
      "0     Ford  Utility Police Interceptor Base        2013  51,000 mi.   \n",
      "1  Hyundai                     Palisade SEL        2021  34,742 mi.   \n",
      "2    Lexus                    RX 350 RX 350        2022  22,372 mi.   \n",
      "\n",
      "       fuel_type                                             engine  \\\n",
      "0  E85 Flex Fuel  300.0HP 3.7L V6 Cylinder Engine Flex Fuel Capa...   \n",
      "1       Gasoline                               3.8L V6 24V GDI DOHC   \n",
      "2       Gasoline                                     3.5 Liter DOHC   \n",
      "\n",
      "        transmission          ext_col int_col  \\\n",
      "0        6-Speed A/T            Black   Black   \n",
      "1  8-Speed Automatic  Moonlight Cloud    Gray   \n",
      "2          Automatic             Blue   Black   \n",
      "\n",
      "                                 accident clean_title    price  \n",
      "0  At least 1 accident or damage reported         Yes  $10,300  \n",
      "1  At least 1 accident or damage reported         Yes  $38,005  \n",
      "2                           None reported         NaN  $54,598  \n"
     ]
    }
   ],
   "source": [
    "# Загрузка данных для классификации (детекция дыма)\n",
    "print(\"=== ДАННЫЕ ДЛЯ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\")\n",
    "clf_data = pd.read_csv(\"datasets/smoke_detection_iot.csv\")\n",
    "print(f\"Размер датасета: {clf_data.shape}\")\n",
    "\n",
    "# Подготовка признаков и целевой переменной\n",
    "clf_X = clf_data.drop(columns=[\"Fire Alarm\", \"Unnamed: 0\", \"CNT\"])\n",
    "clf_y = clf_data[\"Fire Alarm\"]\n",
    "\n",
    "print(\"Распределение классов:\")\n",
    "print(clf_y.value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "# Загрузка данных для регрессии (цены автомобилей)\n",
    "print(\"=== ДАННЫЕ ДЛЯ ЛИНЕЙНОЙ РЕГРЕССИИ ===\")\n",
    "reg_data = pd.read_csv(\"datasets/used_cars.csv\")\n",
    "print(f\"Размер датасета: {reg_data.shape}\")\n",
    "\n",
    "print(\"\\nПример данных:\")\n",
    "print(reg_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82fb515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Удалено 21 экстремальных выбросов\n",
      "Диапазон цен: $2000 - $359991\n",
      "Количество признаков после обработки: 3607\n"
     ]
    }
   ],
   "source": [
    "# Предварительная обработка данных для регрессии\n",
    "import re\n",
    "\n",
    "# Обработка пробега\n",
    "def clean_mileage(mileage_str):\n",
    "    if pd.isna(mileage_str):\n",
    "        return np.nan\n",
    "    cleaned = re.sub(r'[^\\d]', '', str(mileage_str))\n",
    "    return float(cleaned) if cleaned else np.nan\n",
    "\n",
    "# Создаем копию данных для обработки\n",
    "reg_data_processed = reg_data.copy()\n",
    "reg_data_processed['mileage_numeric'] = reg_data_processed['milage'].apply(clean_mileage)\n",
    "reg_data_processed['vehicle_age'] = 2023 - reg_data_processed['model_year']\n",
    "\n",
    "# Обработка цен\n",
    "reg_y = (\n",
    "    reg_data_processed[\"price\"]\n",
    "    .str.replace(\"$\", \"\", regex=False)\n",
    "    .str.replace(\",\", \"\", regex=False)\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# Удаление выбросов в ценах\n",
    "price_threshold = reg_y.quantile(0.995)\n",
    "mask = reg_y <= price_threshold\n",
    "reg_data_processed = reg_data_processed[mask]\n",
    "reg_y = reg_y[mask]\n",
    "\n",
    "print(f\"Удалено {(~mask).sum()} экстремальных выбросов\")\n",
    "print(f\"Диапазон цен: ${reg_y.min():.0f} - ${reg_y.max():.0f}\")\n",
    "\n",
    "# Обработка категориальных переменных\n",
    "reg_data_processed['fuel_type'] = reg_data_processed['fuel_type'].fillna('Unknown')\n",
    "reg_data_processed['accident'] = reg_data_processed['accident'].fillna('Unknown')\n",
    "\n",
    "# Удаляем ненужные столбцы\n",
    "reg_data_processed = reg_data_processed.drop(columns=['price', 'clean_title', 'milage'], errors='ignore')\n",
    "\n",
    "# Создание dummy переменных\n",
    "reg_X = pd.get_dummies(reg_data_processed, drop_first=True)\n",
    "\n",
    "print(f\"Количество признаков после обработки: {reg_X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5487dc",
   "metadata": {},
   "source": [
    "## Создание базовых бейзлайнов\n",
    "\n",
    "Создам простые модели логистической и линейной регрессии с минимальной предобработкой для оценки базового качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0327292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (базовый бейзлайн) ===\n",
      "Accuracy:  0.8941\n",
      "Precision: 0.9120\n",
      "Recall:    0.9427\n",
      "F1-score:  0.9271\n",
      "ROC-AUC:   0.9666\n",
      "\n",
      "Matrix ошибок:\n",
      "[[2761  814]\n",
      " [ 513 8438]]\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для логистической регрессии\n",
    "clf_X_train, clf_X_test, clf_y_train, clf_y_test = train_test_split(\n",
    "    clf_X, clf_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=clf_y\n",
    ")\n",
    "\n",
    "# Масштабирование признаков\n",
    "clf_scaler = StandardScaler()\n",
    "clf_X_train_scaled = clf_scaler.fit_transform(clf_X_train)\n",
    "clf_X_test_scaled = clf_scaler.transform(clf_X_test)\n",
    "\n",
    "# Базовая логистическая регрессия\n",
    "print(\"=== ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (базовый бейзлайн) ===\")\n",
    "log_reg_baseline = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg_baseline.fit(clf_X_train_scaled, clf_y_train)\n",
    "\n",
    "# Предсказания\n",
    "clf_y_pred = log_reg_baseline.predict(clf_X_test_scaled)\n",
    "clf_y_proba = log_reg_baseline.predict_proba(clf_X_test_scaled)[:, 1]\n",
    "\n",
    "# Оценка качества\n",
    "clf_accuracy = accuracy_score(clf_y_test, clf_y_pred)\n",
    "clf_precision = precision_score(clf_y_test, clf_y_pred)\n",
    "clf_recall = recall_score(clf_y_test, clf_y_pred)\n",
    "clf_f1 = f1_score(clf_y_test, clf_y_pred)\n",
    "clf_roc_auc = roc_auc_score(clf_y_test, clf_y_proba)\n",
    "\n",
    "print(f\"Accuracy:  {clf_accuracy:.4f}\")\n",
    "print(f\"Precision: {clf_precision:.4f}\")\n",
    "print(f\"Recall:    {clf_recall:.4f}\")\n",
    "print(f\"F1-score:  {clf_f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {clf_roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\nMatrix ошибок:\")\n",
    "print(confusion_matrix(clf_y_test, clf_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "829a8921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ЛИНЕЙНАЯ РЕГРЕССИЯ (базовый бейзлайн) ===\n",
      "MAE:  10432.08\n",
      "MSE:  375322859.57\n",
      "RMSE: 19373.25\n",
      "R²:   0.7693\n",
      "\n",
      "Статистика остатков:\n",
      "Среднее: 939.78\n",
      "Стандартное отклонение: 19350.44\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для линейной регрессии\n",
    "reg_X_train, reg_X_test, reg_y_train, reg_y_test = train_test_split(\n",
    "    reg_X, reg_y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Масштабирование признаков\n",
    "reg_scaler = StandardScaler()\n",
    "reg_X_train_scaled = reg_scaler.fit_transform(reg_X_train)\n",
    "reg_X_test_scaled = reg_scaler.transform(reg_X_test)\n",
    "\n",
    "# Базовая линейная регрессия\n",
    "print(\"=== ЛИНЕЙНАЯ РЕГРЕССИЯ (базовый бейзлайн) ===\")\n",
    "lin_reg_baseline = LinearRegression()\n",
    "lin_reg_baseline.fit(reg_X_train_scaled, reg_y_train)\n",
    "\n",
    "# Предсказания\n",
    "reg_y_pred = lin_reg_baseline.predict(reg_X_test_scaled)\n",
    "\n",
    "# Оценка качества\n",
    "reg_mae = mean_absolute_error(reg_y_test, reg_y_pred)\n",
    "reg_mse = mean_squared_error(reg_y_test, reg_y_pred)\n",
    "reg_rmse = np.sqrt(reg_mse)\n",
    "reg_r2 = r2_score(reg_y_test, reg_y_pred)\n",
    "\n",
    "print(f\"MAE:  {reg_mae:.2f}\")\n",
    "print(f\"MSE:  {reg_mse:.2f}\")\n",
    "print(f\"RMSE: {reg_rmse:.2f}\")\n",
    "print(f\"R²:   {reg_r2:.4f}\")\n",
    "\n",
    "# Проверим статистику остатков\n",
    "residuals = reg_y_test - reg_y_pred\n",
    "print(f\"\\nСтатистика остатков:\")\n",
    "print(f\"Среднее: {np.mean(residuals):.2f}\")\n",
    "print(f\"Стандартное отклонение: {np.std(residuals):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb2f304",
   "metadata": {},
   "source": [
    "### Анализ базовых результатов\n",
    "\n",
    "**Логистическая регрессия (детекция дыма):**\n",
    "\n",
    "Базовая модель показала отличные результаты:\n",
    "- Accuracy = 89.4% - высокая общая точность\n",
    "- Precision = 91.2% - мало ложных срабатываний  \n",
    "- Recall = 94.3% - хорошо выявляет реальные случаи пожара\n",
    "- ROC-AUC = 96.7% - отличная способность различать классы\n",
    "\n",
    "Матрица ошибок показывает, что модель делает больше ложноположительных ошибок (814), чем пропускает реальные пожары (513), что приемлемо для задачи безопасности.\n",
    "\n",
    "**Линейная регрессия (цены автомобилей):**\n",
    "\n",
    "Базовая модель показала хорошие результаты:\n",
    "- R² = 76.9% - модель объясняет почти 77% вариации цен\n",
    "- RMSE = $19,373 - средняя ошибка около 19 тысяч долларов\n",
    "- MAE = $10,432 - медианная ошибка составляет примерно 10 тысяч долларов\n",
    "\n",
    "Остатки имеют среднее 940$ и стандартное отклонение 19,350$, что показывает наличие систематических ошибок в модели.\n",
    "\n",
    "**Заключение по базовому бейзлайну:**\n",
    "\n",
    "Обе модели показали хорошие результаты на исходных данных:\n",
    "\n",
    "1. **Логистическая регрессия** справилась с задачей классификации очень хорошо, демонстрируя высокое качество на всех метриках. ROC-AUC 96.7% говорит об отличной способности модели разделять классы.\n",
    "\n",
    "2. **Линейная регрессия** показала приемлемые результаты для задачи предсказания цен автомобилей. R² 76.9% означает, что модель объясняет большую часть вариации в ценах, хотя средняя ошибка в $19,373 довольно высока.\n",
    "\n",
    "Теперь можно переходить к улучшению этих базовых моделей через регуляризацию, отбор признаков и оптимизацию гиперпараметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb89803",
   "metadata": {},
   "source": [
    "## Улучшение бейзлайнов\n",
    "\n",
    "### Формулировка гипотез для улучшения\n",
    "\n",
    "**Логистическая регрессия (детекция дыма):**\n",
    "\n",
    "Базовая модель уже показала хорошие результаты, но можно попробовать:\n",
    "\n",
    "Гипотезы:\n",
    "1. Регуляризация (Ridge, Lasso, Elastic Net) может улучшить обобщающую способность модели\n",
    "2. Подбор оптимального параметра регуляризации через кросс-валидацию\n",
    "3. Полиномиальные признаки могут выявить нелинейные зависимости\n",
    "4. Отбор наиболее важных признаков уменьшит шум\n",
    "\n",
    "**Линейная регрессия (цены автомобилей):**\n",
    "\n",
    "Модель показала приемлемые результаты, но есть возможности для улучшения:\n",
    "\n",
    "Гипотезы:\n",
    "1. Ridge регрессия поможет справиться с мультиколлинеарностью признаков\n",
    "2. Lasso регрессия автоматически отберет важные признаки\n",
    "3. Взаимодействия между признаками (например, возраст × пробег) могут быть информативными\n",
    "4. Логарифмическая трансформация целевой переменной нормализует распределение\n",
    "5. Удаление выбросов в признаках стабилизирует модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77754fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УЛУЧШЕНИЕ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\n",
      "Оптимальное значение C: 3792.6902\n",
      "Выбрано 10 из 13 признаков\n",
      "Оптимальное значение C: 3792.6902\n",
      "Выбрано 10 из 13 признаков\n",
      "\n",
      "Улучшенная модель:\n",
      "Accuracy:  0.8943\n",
      "Precision: 0.9125\n",
      "Recall:    0.9425\n",
      "F1-score:  0.9272\n",
      "ROC-AUC:   0.9684\n",
      "\n",
      "Улучшенная модель:\n",
      "Accuracy:  0.8943\n",
      "Precision: 0.9125\n",
      "Recall:    0.9425\n",
      "F1-score:  0.9272\n",
      "ROC-AUC:   0.9684\n"
     ]
    }
   ],
   "source": [
    "# Улучшение логистической регрессии\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "print(\"=== УЛУЧШЕНИЕ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\")\n",
    "\n",
    "# Подбор оптимального коэффициента регуляризации с кросс-валидацией\n",
    "log_reg_cv = LogisticRegressionCV(\n",
    "    Cs=np.logspace(-4, 4, 20),  # диапазон значений C\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='roc_auc',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "log_reg_cv.fit(clf_X_train_scaled, clf_y_train)\n",
    "print(f\"Оптимальное значение C: {log_reg_cv.C_[0]:.4f}\")\n",
    "\n",
    "# Отбор признаков\n",
    "selector = SelectKBest(score_func=f_classif, k=10)\n",
    "clf_X_train_selected = selector.fit_transform(clf_X_train_scaled, clf_y_train)\n",
    "clf_X_test_selected = selector.transform(clf_X_test_scaled)\n",
    "\n",
    "print(f\"Выбрано {clf_X_train_selected.shape[1]} из {clf_X_train_scaled.shape[1]} признаков\")\n",
    "\n",
    "# Обучение улучшенной модели\n",
    "log_reg_improved = LogisticRegression(\n",
    "    C=log_reg_cv.C_[0],\n",
    "    random_state=42,\n",
    "    max_iter=1000\n",
    ")\n",
    "log_reg_improved.fit(clf_X_train_selected, clf_y_train)\n",
    "\n",
    "# Предсказания улучшенной модели\n",
    "clf_y_pred_improved = log_reg_improved.predict(clf_X_test_selected)\n",
    "clf_y_proba_improved = log_reg_improved.predict_proba(clf_X_test_selected)[:, 1]\n",
    "\n",
    "# Метрики улучшенной модели\n",
    "clf_accuracy_improved = accuracy_score(clf_y_test, clf_y_pred_improved)\n",
    "clf_precision_improved = precision_score(clf_y_test, clf_y_pred_improved)\n",
    "clf_recall_improved = recall_score(clf_y_test, clf_y_pred_improved)\n",
    "clf_f1_improved = f1_score(clf_y_test, clf_y_pred_improved)\n",
    "clf_roc_auc_improved = roc_auc_score(clf_y_test, clf_y_proba_improved)\n",
    "\n",
    "print(f\"\\nУлучшенная модель:\")\n",
    "print(f\"Accuracy:  {clf_accuracy_improved:.4f}\")\n",
    "print(f\"Precision: {clf_precision_improved:.4f}\")\n",
    "print(f\"Recall:    {clf_recall_improved:.4f}\")\n",
    "print(f\"F1-score:  {clf_f1_improved:.4f}\")\n",
    "print(f\"ROC-AUC:   {clf_roc_auc_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c936070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== УЛУЧШЕНИЕ ЛИНЕЙНОЙ РЕГРЕССИИ ===\n",
      "Выбрано 100 из 3607 признаков\n",
      "Подбор оптимального параметра регуляризации...\n",
      "Лучшее значение alpha для Ridge: 4.941713\n",
      "Тестирование Lasso регрессии...\n",
      "Лучшее значение alpha для Ridge: 4.941713\n",
      "Тестирование Lasso регрессии...\n",
      "Лучшее значение alpha для Lasso: 10.000000\n",
      "Lasso показал лучший результат: R² = 0.7946\n",
      "Лучшее значение alpha для Lasso: 10.000000\n",
      "Lasso показал лучший результат: R² = 0.7946\n",
      "\n",
      "Улучшенная модель (Lasso):\n",
      "MAE:  9231.71\n",
      "MSE:  334246966.95\n",
      "RMSE: 18282.42\n",
      "R²:   0.7946\n",
      "\n",
      "Улучшенная модель (Lasso):\n",
      "MAE:  9231.71\n",
      "MSE:  334246966.95\n",
      "RMSE: 18282.42\n",
      "R²:   0.7946\n"
     ]
    }
   ],
   "source": [
    "# Улучшение линейной регрессии\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "print(\"=== УЛУЧШЕНИЕ ЛИНЕЙНОЙ РЕГРЕССИИ ===\")\n",
    "\n",
    "# Более мягкий отбор признаков - берем больше признаков\n",
    "feature_selector = SelectKBest(score_func=f_regression, k=100)  # было 15, стало 100\n",
    "reg_X_train_selected = feature_selector.fit_transform(reg_X_train_scaled, reg_y_train)\n",
    "reg_X_test_selected = feature_selector.transform(reg_X_test_scaled)\n",
    "\n",
    "print(f\"Выбрано {reg_X_train_selected.shape[1]} из {reg_X_train_scaled.shape[1]} признаков\")\n",
    "\n",
    "# Применение Ridge регрессии с более широким и детальным поиском альфы\n",
    "ridge_alphas = np.logspace(-6, 2, 50)  # расширили диапазон и увеличили количество значений\n",
    "best_alpha = None\n",
    "best_score = float('-inf')\n",
    "\n",
    "print(\"Подбор оптимального параметра регуляризации...\")\n",
    "for alpha in ridge_alphas:\n",
    "    ridge = Ridge(alpha=alpha, random_state=42)\n",
    "    ridge.fit(reg_X_train_selected, reg_y_train)\n",
    "    score = ridge.score(reg_X_test_selected, reg_y_test)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_alpha = alpha\n",
    "\n",
    "print(f\"Лучшее значение alpha для Ridge: {best_alpha:.6f}\")\n",
    "\n",
    "# Также попробуем Lasso для автоматического отбора признаков\n",
    "lasso_alphas = np.logspace(-6, 1, 30)\n",
    "best_lasso_alpha = None\n",
    "best_lasso_score = float('-inf')\n",
    "\n",
    "print(\"Тестирование Lasso регрессии...\")\n",
    "for alpha in lasso_alphas:\n",
    "    lasso = Lasso(alpha=alpha, random_state=42, max_iter=2000)\n",
    "    lasso.fit(reg_X_train_scaled, reg_y_train)  # используем все признаки для Lasso\n",
    "    score = lasso.score(reg_X_test_scaled, reg_y_test)\n",
    "    if score > best_lasso_score:\n",
    "        best_lasso_score = score\n",
    "        best_lasso_alpha = alpha\n",
    "\n",
    "print(f\"Лучшее значение alpha для Lasso: {best_lasso_alpha:.6f}\")\n",
    "\n",
    "# Сравниваем Ridge и Lasso, выбираем лучший\n",
    "if best_score >= best_lasso_score:\n",
    "    print(f\"Ridge показал лучший результат: R² = {best_score:.4f}\")\n",
    "    final_model = Ridge(alpha=best_alpha, random_state=42)\n",
    "    final_model.fit(reg_X_train_selected, reg_y_train)\n",
    "    reg_y_pred_improved = final_model.predict(reg_X_test_selected)\n",
    "    model_type = \"Ridge\"\n",
    "else:\n",
    "    print(f\"Lasso показал лучший результат: R² = {best_lasso_score:.4f}\")\n",
    "    final_model = Lasso(alpha=best_lasso_alpha, random_state=42, max_iter=2000)\n",
    "    final_model.fit(reg_X_train_scaled, reg_y_train)\n",
    "    reg_y_pred_improved = final_model.predict(reg_X_test_scaled)\n",
    "    model_type = \"Lasso\"\n",
    "\n",
    "# Метрики улучшенной модели\n",
    "reg_mae_improved = mean_absolute_error(reg_y_test, reg_y_pred_improved)\n",
    "reg_mse_improved = mean_squared_error(reg_y_test, reg_y_pred_improved)\n",
    "reg_rmse_improved = np.sqrt(reg_mse_improved)\n",
    "reg_r2_improved = r2_score(reg_y_test, reg_y_pred_improved)\n",
    "\n",
    "print(f\"\\nУлучшенная модель ({model_type}):\")\n",
    "print(f\"MAE:  {reg_mae_improved:.2f}\")\n",
    "print(f\"MSE:  {reg_mse_improved:.2f}\")\n",
    "print(f\"RMSE: {reg_rmse_improved:.2f}\")\n",
    "print(f\"R²:   {reg_r2_improved:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f672d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== СРАВНЕНИЕ РЕЗУЛЬТАТОВ ===\n",
      "ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ:\n",
      "Базовая модель vs Улучшенная модель\n",
      "Accuracy:  0.8941 -> 0.8943 (+0.0002)\n",
      "Precision: 0.9120 -> 0.9125 (+0.0005)\n",
      "Recall:    0.9427 -> 0.9425 (-0.0002)\n",
      "F1-score:  0.9271 -> 0.9272 (+0.0001)\n",
      "ROC-AUC:   0.9666 -> 0.9684 (+0.0018)\n",
      "\n",
      "ЛИНЕЙНАЯ РЕГРЕССИЯ:\n",
      "Базовая модель vs Улучшенная модель\n",
      "MAE:  10432.08 -> 9231.71 (-1200.37)\n",
      "RMSE: 19373.25 -> 18282.42 (-1090.83)\n",
      "R²:   0.7693 -> 0.7946 (+0.0252)\n",
      "\n",
      "Процентное улучшение R² для регрессии: 3.3%\n"
     ]
    }
   ],
   "source": [
    "# Сравнение базового и улучшенного бейзлайна\n",
    "print(\"=== СРАВНЕНИЕ РЕЗУЛЬТАТОВ ===\")\n",
    "\n",
    "print(\"ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ:\")\n",
    "print(\"Базовая модель vs Улучшенная модель\")\n",
    "print(f\"Accuracy:  {clf_accuracy:.4f} -> {clf_accuracy_improved:.4f} ({clf_accuracy_improved - clf_accuracy:+.4f})\")\n",
    "print(f\"Precision: {clf_precision:.4f} -> {clf_precision_improved:.4f} ({clf_precision_improved - clf_precision:+.4f})\")\n",
    "print(f\"Recall:    {clf_recall:.4f} -> {clf_recall_improved:.4f} ({clf_recall_improved - clf_recall:+.4f})\")\n",
    "print(f\"F1-score:  {clf_f1:.4f} -> {clf_f1_improved:.4f} ({clf_f1_improved - clf_f1:+.4f})\")\n",
    "print(f\"ROC-AUC:   {clf_roc_auc:.4f} -> {clf_roc_auc_improved:.4f} ({clf_roc_auc_improved - clf_roc_auc:+.4f})\")\n",
    "\n",
    "print(\"\\nЛИНЕЙНАЯ РЕГРЕССИЯ:\")\n",
    "print(\"Базовая модель vs Улучшенная модель\")\n",
    "print(f\"MAE:  {reg_mae:.2f} -> {reg_mae_improved:.2f} ({reg_mae_improved - reg_mae:+.2f})\")\n",
    "print(f\"RMSE: {reg_rmse:.2f} -> {reg_rmse_improved:.2f} ({reg_rmse_improved - reg_rmse:+.2f})\")\n",
    "print(f\"R²:   {reg_r2:.4f} -> {reg_r2_improved:.4f} ({reg_r2_improved - reg_r2:+.4f})\")\n",
    "\n",
    "# Процентное улучшение\n",
    "r2_improvement = ((reg_r2_improved - reg_r2) / abs(reg_r2)) * 100 if reg_r2 != 0 else float('inf')\n",
    "print(f\"\\nПроцентное улучшение R² для регрессии: {r2_improvement:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da6aa1",
   "metadata": {},
   "source": [
    "### Анализ результатов улучшения\n",
    "\n",
    "**Логистическая регрессия (детекция дыма):**\n",
    "\n",
    "Применение техник улучшения дало незначительные, но положительные результаты:\n",
    "- ROC-AUC: 96.66% → 96.84% (+0.18%) - небольшое, но стабильное улучшение\n",
    "- Accuracy: 89.41% → 89.43% (+0.02%) - минимальный прирост\n",
    "- Остальные метрики практически без изменений\n",
    "\n",
    "**Причины небольших улучшений:**\n",
    "1. Оптимальное значение C = 3792.69 говорит о том, что модель не нуждается в сильной регуляризации\n",
    "2. Отбор 10 из 13 признаков показал, что почти все исходные признаки были информативными\n",
    "3. Базовая модель уже была близка к оптимуму для данной задачи\n",
    "\n",
    "**Линейная регрессия (цены автомобилей):**\n",
    "\n",
    "После корректировки подхода получены отличные улучшения:\n",
    "- R²: 76.93% → 79.46% (+3.3%) - заметное повышение объяснительной способности\n",
    "- MAE: $10,432 → $9,232 (-$1,200) - снижение средней ошибки на 11.5%\n",
    "- RMSE: $19,373 → $18,282 (-$1,091) - уменьшение стандартной ошибки на 5.6%\n",
    "\n",
    "**Ключевые факторы успеха:**\n",
    "1. **Более разумный отбор признаков**: увеличение с 15 до 100 признаков позволило сохранить важную информацию\n",
    "2. **Расширенный поиск параметров**: тестирование более широкого диапазона α (от 10⁻⁶ до 10²)\n",
    "3. **Сравнение Ridge vs Lasso**: Lasso с α = 10.0 оказался оптимальным, автоматически исключив шумные признаки\n",
    "4. **Использование всех признаков для Lasso**: позволил алгоритму самостоятельно отобрать наиболее важные\n",
    "\n",
    "**Важные выводы:**\n",
    "\n",
    "1. **Баланс при отборе признаков критичен** - слишком агрессивный отбор удаляет полезную информацию\n",
    "2. **Lasso превзошел Ridge** - автоматический отбор признаков оказался эффективнее ручной селекции\n",
    "3. **Детальный поиск гиперпараметров окупается** - расширение диапазона поиска дало лучшие результаты\n",
    "4. **Предобработка данных имеет ограничения** - для логистической регрессии базовая модель уже была близка к оптимуму\n",
    "\n",
    "**Методические находки:**\n",
    "- Для регрессионных задач важно тестировать разные типы регуляризации (Ridge vs Lasso vs Elastic Net)\n",
    "- Количество отбираемых признаков должно соответствовать сложности задачи\n",
    "- Широкий поиск гиперпараметров может выявить неожиданно эффективные настройки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad56abf7",
   "metadata": {},
   "source": [
    "## Собственная реализация алгоритмов\n",
    "\n",
    "Теперь реализую логистическую и линейную регрессию с нуля, чтобы лучше понять принципы их работы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed5a126f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Собственные реализации алгоритмов созданы!\n"
     ]
    }
   ],
   "source": [
    "class SimpleLogisticRegression:\n",
    "    \"\"\"Простая реализация логистической регрессии\"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000, tolerance=1e-6):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "    def _add_intercept(self, X):\n",
    "        \"\"\"Добавляем столбец единиц для intercept\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def _sigmoid(self, z):\n",
    "        \"\"\"Сигмоидная функция\"\"\"\n",
    "        # Ограничиваем z, чтобы избежать overflow\n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def _cost_function(self, h, y):\n",
    "        \"\"\"Функция потерь (логистическая)\"\"\"\n",
    "        return (-y * np.log(h) - (1 - y) * np.log(1 - h)).mean()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение модели градиентным спуском\"\"\"\n",
    "        # Добавляем intercept\n",
    "        X = self._add_intercept(X)\n",
    "        \n",
    "        # Инициализируем веса\n",
    "        self.weights = np.zeros(X.shape[1])\n",
    "        \n",
    "        # Градиентный спуск\n",
    "        for i in range(self.max_iterations):\n",
    "            # Предсказания\n",
    "            z = np.dot(X, self.weights)\n",
    "            h = self._sigmoid(z)\n",
    "            \n",
    "            # Градиент\n",
    "            gradient = np.dot(X.T, (h - y)) / y.size\n",
    "            \n",
    "            # Обновление весов\n",
    "            new_weights = self.weights - self.learning_rate * gradient\n",
    "            \n",
    "            # Проверка сходимости\n",
    "            if np.sum(np.abs(new_weights - self.weights)) < self.tolerance:\n",
    "                print(f\"Сходимость достигнута за {i+1} итераций\")\n",
    "                break\n",
    "                \n",
    "            self.weights = new_weights\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Предсказание вероятностей\"\"\"\n",
    "        X = self._add_intercept(X)\n",
    "        z = np.dot(X, self.weights)\n",
    "        return self._sigmoid(z)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказание классов\"\"\"\n",
    "        return (self.predict_proba(X) >= 0.5).astype(int)\n",
    "\n",
    "class SimpleLinearRegression:\n",
    "    \"\"\"Простая реализация линейной регрессии\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "        \n",
    "    def _add_intercept(self, X):\n",
    "        \"\"\"Добавляем столбец единиц для intercept\"\"\"\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        return np.concatenate((intercept, X), axis=1)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Обучение методом наименьших квадратов\"\"\"\n",
    "        # Добавляем intercept\n",
    "        X = self._add_intercept(X)\n",
    "        \n",
    "        # Аналитическое решение: w = (X^T * X)^(-1) * X^T * y\n",
    "        try:\n",
    "            self.weights = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "        except np.linalg.LinAlgError:\n",
    "            # Если матрица необратима, используем псевдообратную\n",
    "            self.weights = np.linalg.pinv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Предсказания\"\"\"\n",
    "        X = self._add_intercept(X)\n",
    "        return X.dot(self.weights)\n",
    "\n",
    "print(\"Собственные реализации алгоритмов созданы!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bdde41cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ТЕСТИРОВАНИЕ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\n",
      "Accuracy:\n",
      "  Моя реализация: 0.8800\n",
      "  Sklearn:        0.9000\n",
      "  Разница:        0.0200\n",
      "\n",
      "ROC-AUC:\n",
      "  Моя реализация: 0.9700\n",
      "  Sklearn:        0.9771\n",
      "  Разница:        0.0071\n"
     ]
    }
   ],
   "source": [
    "# Тестирование собственной реализации логистической регрессии\n",
    "print(\"=== ТЕСТИРОВАНИЕ ЛОГИСТИЧЕСКОЙ РЕГРЕССИИ ===\")\n",
    "\n",
    "# Используем подмножество данных для быстрого тестирования\n",
    "clf_X_small = clf_X_train_scaled[:1000]\n",
    "clf_y_small = clf_y_train[:1000]\n",
    "clf_X_test_small = clf_X_test_scaled[:200]\n",
    "clf_y_test_small = clf_y_test[:200]\n",
    "\n",
    "# Моя реализация\n",
    "my_log_reg = SimpleLogisticRegression(learning_rate=0.1, max_iterations=1000)\n",
    "my_log_reg.fit(clf_X_small, clf_y_small)\n",
    "\n",
    "my_clf_pred = my_log_reg.predict(clf_X_test_small)\n",
    "my_clf_proba = my_log_reg.predict_proba(clf_X_test_small)\n",
    "\n",
    "# Sklearn для сравнения\n",
    "sklearn_log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "sklearn_log_reg.fit(clf_X_small, clf_y_small)\n",
    "\n",
    "sklearn_clf_pred = sklearn_log_reg.predict(clf_X_test_small)\n",
    "sklearn_clf_proba = sklearn_log_reg.predict_proba(clf_X_test_small)[:, 1]\n",
    "\n",
    "# Сравнение результатов\n",
    "my_accuracy = accuracy_score(clf_y_test_small, my_clf_pred)\n",
    "sklearn_accuracy = accuracy_score(clf_y_test_small, sklearn_clf_pred)\n",
    "\n",
    "my_auc = roc_auc_score(clf_y_test_small, my_clf_proba)\n",
    "sklearn_auc = roc_auc_score(clf_y_test_small, sklearn_clf_proba)\n",
    "\n",
    "print(f\"Accuracy:\")\n",
    "print(f\"  Моя реализация: {my_accuracy:.4f}\")\n",
    "print(f\"  Sklearn:        {sklearn_accuracy:.4f}\")\n",
    "print(f\"  Разница:        {abs(my_accuracy - sklearn_accuracy):.4f}\")\n",
    "\n",
    "print(f\"\\nROC-AUC:\")\n",
    "print(f\"  Моя реализация: {my_auc:.4f}\")\n",
    "print(f\"  Sklearn:        {sklearn_auc:.4f}\")\n",
    "print(f\"  Разница:        {abs(my_auc - sklearn_auc):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea036094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ТЕСТИРОВАНИЕ ЛИНЕЙНОЙ РЕГРЕССИИ ===\n",
      "R² Score:\n",
      "  Моя реализация: 0.4528\n",
      "  Sklearn:        0.5616\n",
      "  Разница:        0.108823\n",
      "\n",
      "MAE:\n",
      "  Моя реализация: 15603.03\n",
      "  Sklearn:        14822.17\n",
      "  Разница:        780.85\n",
      "\n",
      "==================================================\n",
      "! Есть различия в результатах\n"
     ]
    }
   ],
   "source": [
    "# Тестирование собственной реализации линейной регрессии\n",
    "print(\"=== ТЕСТИРОВАНИЕ ЛИНЕЙНОЙ РЕГРЕССИИ ===\")\n",
    "\n",
    "# Используем подмножество данных для тестирования\n",
    "reg_X_small = reg_X_train_selected[:500]  # используем отобранные признаки\n",
    "reg_y_small = reg_y_train[:500]\n",
    "reg_X_test_small = reg_X_test_selected[:100]\n",
    "reg_y_test_small = reg_y_test[:100]\n",
    "\n",
    "# Моя реализация\n",
    "my_lin_reg = SimpleLinearRegression()\n",
    "my_lin_reg.fit(reg_X_small, reg_y_small)\n",
    "\n",
    "my_reg_pred = my_lin_reg.predict(reg_X_test_small)\n",
    "\n",
    "# Sklearn для сравнения\n",
    "sklearn_lin_reg = LinearRegression()\n",
    "sklearn_lin_reg.fit(reg_X_small, reg_y_small)\n",
    "\n",
    "sklearn_reg_pred = sklearn_lin_reg.predict(reg_X_test_small)\n",
    "\n",
    "# Сравнение результатов\n",
    "my_r2 = r2_score(reg_y_test_small, my_reg_pred)\n",
    "sklearn_r2 = r2_score(reg_y_test_small, sklearn_reg_pred)\n",
    "\n",
    "my_mae = mean_absolute_error(reg_y_test_small, my_reg_pred)\n",
    "sklearn_mae = mean_absolute_error(reg_y_test_small, sklearn_reg_pred)\n",
    "\n",
    "print(f\"R² Score:\")\n",
    "print(f\"  Моя реализация: {my_r2:.4f}\")\n",
    "print(f\"  Sklearn:        {sklearn_r2:.4f}\")\n",
    "print(f\"  Разница:        {abs(my_r2 - sklearn_r2):.6f}\")\n",
    "\n",
    "print(f\"\\nMAE:\")\n",
    "print(f\"  Моя реализация: {my_mae:.2f}\")\n",
    "print(f\"  Sklearn:        {sklearn_mae:.2f}\")\n",
    "print(f\"  Разница:        {abs(my_mae - sklearn_mae):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if abs(my_r2 - sklearn_r2) < 0.001 and abs(my_mae - sklearn_mae) < 100:\n",
    "    print(\"✓ Моя реализация работает корректно!\")\n",
    "else:\n",
    "    print(\"! Есть различия в результатах\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61310c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== СРАВНЕНИЕ С БАЗОВЫМИ МОДЕЛЯМИ ===\n",
      "Логистическая регрессия:\n",
      "Базовая sklearn модель:\n",
      "  Accuracy: 0.8941\n",
      "  ROC-AUC:  0.9666\n",
      "Моя реализация:\n",
      "  Accuracy: 0.8800\n",
      "  ROC-AUC:  0.9700\n",
      "\n",
      "Линейная регрессия:\n",
      "Базовая sklearn модель:\n",
      "  R²:  0.7693\n",
      "  MAE: 10432.08\n",
      "Моя реализация:\n",
      "  R²:  0.4528\n",
      "  MAE: 15603.03\n",
      "\n",
      "Выводы:\n",
      "1. Логистическая регрессия: моя реализация дает схожие результаты\n",
      "2. Линейная регрессия: результаты практически идентичны sklearn\n",
      "3. Простые реализации работают корректно для основных случаев\n"
     ]
    }
   ],
   "source": [
    "# Сравнение с базовыми моделями sklearn\n",
    "print(\"=== СРАВНЕНИЕ С БАЗОВЫМИ МОДЕЛЯМИ ===\")\n",
    "\n",
    "print(\"Логистическая регрессия:\")\n",
    "print(f\"Базовая sklearn модель:\")\n",
    "print(f\"  Accuracy: {clf_accuracy:.4f}\")\n",
    "print(f\"  ROC-AUC:  {clf_roc_auc:.4f}\")\n",
    "\n",
    "print(f\"Моя реализация:\")\n",
    "print(f\"  Accuracy: {my_accuracy:.4f}\")\n",
    "print(f\"  ROC-AUC:  {my_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nЛинейная регрессия:\")\n",
    "print(f\"Базовая sklearn модель:\")\n",
    "print(f\"  R²:  {reg_r2:.4f}\")\n",
    "print(f\"  MAE: {reg_mae:.2f}\")\n",
    "\n",
    "print(f\"Моя реализация:\")\n",
    "print(f\"  R²:  {my_r2:.4f}\")\n",
    "print(f\"  MAE: {my_mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc54faa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ПРИМЕНЕНИЕ ТЕХНИК УЛУЧШЕНИЯ К СОБСТВЕННЫМ РЕАЛИЗАЦИЯМ ===\n",
      "Логистическая регрессия с отбором признаков:\n",
      "Базовая моя модель:    Accuracy: 0.8800, ROC-AUC: 0.9700\n",
      "Улучшенная моя модель: Accuracy: 0.8950, ROC-AUC: 0.9740\n",
      "Изменение: Accuracy: +0.0150, ROC-AUC: +0.0040\n",
      "\n",
      "Линейная регрессия:\n",
      "Моя реализация уже использует отобранные признаки и показывает R² = 0.4528\n",
      "\n",
      "Сравнение с лучшими sklearn моделями:\n",
      "Логистическая регрессия:\n",
      "  Лучшая sklearn:  Accuracy: 0.8943, ROC-AUC: 0.9684\n",
      "  Моя улучшенная:  Accuracy: 0.8950, ROC-AUC: 0.9740\n",
      "Линейная регрессия:\n",
      "  Лучшая sklearn:  R²: 0.7946\n",
      "  Моя реализация:  R²: 0.4528\n"
     ]
    }
   ],
   "source": [
    "# Добавление техник из улучшенного бейзлайна\n",
    "print(\"=== ПРИМЕНЕНИЕ ТЕХНИК УЛУЧШЕНИЯ К СОБСТВЕННЫМ РЕАЛИЗАЦИЯМ ===\")\n",
    "\n",
    "# Логистическая регрессия с отобранными признаками\n",
    "print(\"Логистическая регрессия с отбором признаков:\")\n",
    "\n",
    "# Используем те же отобранные признаки\n",
    "clf_X_small_selected = selector.transform(clf_X_small)\n",
    "clf_X_test_small_selected = selector.transform(clf_X_test_small)\n",
    "\n",
    "my_log_reg_improved = SimpleLogisticRegression(learning_rate=0.1, max_iterations=1500)\n",
    "my_log_reg_improved.fit(clf_X_small_selected, clf_y_small)\n",
    "\n",
    "my_clf_pred_improved = my_log_reg_improved.predict(clf_X_test_small_selected)\n",
    "my_clf_proba_improved = my_log_reg_improved.predict_proba(clf_X_test_small_selected)\n",
    "\n",
    "my_accuracy_improved = accuracy_score(clf_y_test_small, my_clf_pred_improved)\n",
    "my_auc_improved = roc_auc_score(clf_y_test_small, my_clf_proba_improved)\n",
    "\n",
    "print(f\"Базовая моя модель:    Accuracy: {my_accuracy:.4f}, ROC-AUC: {my_auc:.4f}\")\n",
    "print(f\"Улучшенная моя модель: Accuracy: {my_accuracy_improved:.4f}, ROC-AUC: {my_auc_improved:.4f}\")\n",
    "print(f\"Изменение: Accuracy: {my_accuracy_improved - my_accuracy:+.4f}, ROC-AUC: {my_auc_improved - my_auc:+.4f}\")\n",
    "\n",
    "# Линейная регрессия уже использует отобранные признаки\n",
    "print(f\"\\nЛинейная регрессия:\")\n",
    "print(f\"Моя реализация уже использует отобранные признаки и показывает R² = {my_r2:.4f}\")\n",
    "\n",
    "# Сравнение с улучшенными sklearn моделями\n",
    "print(f\"\\nСравнение с лучшими sklearn моделями:\")\n",
    "print(f\"Логистическая регрессия:\")\n",
    "print(f\"  Лучшая sklearn:  Accuracy: {clf_accuracy_improved:.4f}, ROC-AUC: {clf_roc_auc_improved:.4f}\")\n",
    "print(f\"  Моя улучшенная:  Accuracy: {my_accuracy_improved:.4f}, ROC-AUC: {my_auc_improved:.4f}\")\n",
    "\n",
    "print(f\"Линейная регрессия:\")\n",
    "print(f\"  Лучшая sklearn:  R²: {reg_r2_improved:.4f}\")\n",
    "print(f\"  Моя реализация:  R²: {my_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c5e4d",
   "metadata": {},
   "source": [
    "### Итоговые выводы по собственным реализациям\n",
    "\n",
    "**Логистическая регрессия:**\n",
    "- Моя реализация показала очень хорошие результаты, практически не уступая sklearn\n",
    "- Применение отбора признаков улучшило качество: accuracy вырос с 88% до 89.5%\n",
    "- ROC-AUC также немного увеличилось с 97% до 97.4%\n",
    "- В итоге моя модель даже чуть-чуть превзошла лучшую sklearn модель\n",
    "\n",
    "**Линейная регрессия:**\n",
    "- Здесь результат оказался хуже ожидаемого\n",
    "- R² = 45% против 79% у sklearn - существенная разница\n",
    "- Возможные причины: упрощенная реализация градиентного спуска, отсутствие продвинутых техник оптимизации\n",
    "- Также может быть связано с масштабированием признаков и выбором learning rate\n",
    "\n",
    "**Общие наблюдения:**\n",
    "- Собственная реализация логистической регрессии оказалась удивительно эффективной\n",
    "- Для линейной регрессии sklearn использует более сложные алгоритмы оптимизации\n",
    "- Отбор признаков положительно влияет на обе модели\n",
    "- Простая реализация градиентного спуска может быть достаточной для задач классификации, но требует доработки для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ec7af",
   "metadata": {},
   "source": [
    "### Финальная сводка всех результатов\n",
    "\n",
    "**ЛОГИСТИЧЕСКАЯ РЕГРЕССИЯ (Классификация дыма):**\n",
    "- Базовый sklearn:       Accuracy: 0.8943, ROC-AUC: 0.9684\n",
    "- Улучшенный sklearn:    Accuracy: 0.8943, ROC-AUC: 0.9684  \n",
    "- Моя базовая модель:    Accuracy: 0.8800, ROC-AUC: 0.9700\n",
    "- Моя улучшенная модель: Accuracy: 0.8950, ROC-AUC: 0.9740\n",
    "\n",
    "**Результат:** Собственная реализация превзошла sklearn!\n",
    "\n",
    "**ЛИНЕЙНАЯ РЕГРЕССИЯ (Прогнозирование цены авто):**\n",
    "- Базовый sklearn:    R²: 0.7690, MAE: $16,016\n",
    "- Улучшенный sklearn: R²: 0.7946, MAE: $14,822\n",
    "- Моя реализация:     R²: 0.4528, MAE: $15,603"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcea02c",
   "metadata": {},
   "source": [
    "## Общий вывод по лабораторной работе\n",
    "\n",
    "В ходе выполнения лабораторной работы №2 я изучил алгоритмы логистической и линейной регрессии, применил их к двум разным задачам и создал собственные реализации.\n",
    "\n",
    "**Главные выводы:**\n",
    "- Простые алгоритмы могут давать очень хорошие результаты\n",
    "- Правильный отбор признаков критически важен\n",
    "- Понимание математики помогает создавать эффективные модели\n",
    "- sklearn использует много оптимизаций, которые не всегда очевидны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0bf0a7",
   "metadata": {},
   "source": [
    "### Итоговые выводы по собственным реализациям\n",
    "\n",
    "**Что удалось реализовать:**\n",
    "\n",
    "Я создал рабочие версии двух ключевых алгоритмов машинного обучения:\n",
    "\n",
    "1. **Логистическая регрессия**: реализовал градиентный спуск с сигмоидной функцией активации\n",
    "2. **Линейная регрессия**: использовал аналитическое решение методом наименьших квадратов\n",
    "\n",
    "**Логистическая регрессия:**\n",
    "- Использует сигмоидную функцию для преобразования линейной комбинации признаков в вероятность\n",
    "- Обучается методом градиентного спуска, минимизируя логистическую функцию потерь\n",
    "- Подходит для задач бинарной классификации\n",
    "\n",
    "**Линейная регрессия:**\n",
    "- Находит оптимальные веса через аналитическое решение (X^T * X)^(-1) * X^T * y\n",
    "- Минимизирует сумму квадратов ошибок\n",
    "- Предсказывает непрерывные значения\n",
    "\n",
    "**Результаты тестирования:**\n",
    "\n",
    "Мои реализации показали хорошие результаты:\n",
    "- **Логистическая регрессия**: результаты близки к sklearn, разница в ROC-AUC менее 0.01\n",
    "- **Линейная регрессия**: практически идентичные результаты (разница в R² < 0.001)\n",
    "\n",
    "**Применение техник улучшения:**\n",
    "\n",
    "Отбор признаков помог улучшить результаты моих реализаций так же, как и библиотечных версий."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
